---
title: "DStack Architecture"
description: "A comprehensive exploration of dstack's architecture, detailing its components, innovations, and zero-trust principles for confidential containers in Web3."
---

# DStack Architecture Deep Dive

This document offers a thorough exploration of dstack’s architecture, a zero-trust platform engineered to deliver secure, decentralized, and verifiable computing for Web3 applications. By harnessing Trusted Execution Environments (TEEs), dstack introduces a novel approach to confidential containers, ensuring that data and code remain protected, portable, and transparent across diverse hardware environments. Here, we dissect the platform’s core components, their interplay, and the innovations that distinguish dstack as a leader in confidential computing.

## Introduction

dstack addresses the critical need for secure, decentralized application deployment in Web3, where traditional trust models fall short. It leverages TEEs—hardware-based isolation mechanisms like Intel TDX, AMD SEV-SNP, and ARM CCA—to create confidential containers. These containers safeguard data confidentiality, code integrity, and operational verifiability without dependence on centralized authorities. Unlike conventional TEE implementations, which suffer from vendor lock-in, censorship vulnerabilities, and incomplete trust chains, dstack introduces a robust architecture built on three foundational innovations: Portable Confidential Containers, Decentralized Code Management, and Verifiable Domain Management. This deep dive unpacks these concepts and the technical machinery that brings them to life.


## System Design

At its core, dstack’s architecture revolves around the seamless integration of four primary components: dstack-os, dstack-kms, dstack-ingress, and dstack-gateway. Together, they form a cohesive system that abstracts hardware differences, manages cryptographic keys, and secures communication channels—all while adhering to Web3’s decentralized ethos.

dstack-os serves as the hardware abstraction layer, providing a consistent runtime environment across disparate TEE platforms. dstack-kms handles key management with blockchain oversight, ensuring keys are portable and secure. Meanwhile, dstack-ingress and dstack-gateway facilitate secure, verifiable communication between applications and users. This design ensures that confidential containers can be deployed, executed, and accessed with end-to-end security and transparency.

## Deep Dive into Components

### dstack-os: Hardware Abstraction Layer

dstack-os is a lightweight operating system optimized for TEEs, engineered to bridge the gap between diverse hardware implementations. Its primary role is to provide a uniform runtime environment, enabling applications to operate seamlessly across Intel, AMD, or ARM TEEs without modification.

The secure boot process of dstack-os establishes a verifiable chain of trust. Starting with the hypervisor, each layer measures the subsequent one—recording cryptographic digests in hardware registers such as MRTD and RTMR0-3 (specific to Intel TDX, with analogous registers in other TEEs). For instance, the hypervisor loads the Open Virtual Machine Firmware (OVMF), which configures the virtual machine and loads the Linux kernel. The kernel then initializes the root filesystem, which manages application execution. Each step’s measurement is captured in the TEE’s attestation report, allowing external parties to verify the system’s integrity.

To minimize vulnerabilities, dstack-os adopts a lean design, incorporating only essential utilities like busybox, filesystem support, and a container runtime. This reduced footprint shrinks the attack surface and simplifies auditing. Furthermore, its open-source codebase and reproducible builds enable independent verification, ensuring the deployed image matches the reviewed source. Data security is reinforced through dm-verity for block-level integrity and LUKS for disk encryption, with keys sourced from dstack-kms to maintain portability across TEE instances.


### dstack-kms: Blockchain-Controlled Key Management

dstack-kms is the cryptographic backbone of dstack, delivering a decentralized key management service that liberates keys from hardware-specific constraints. This independence is pivotal for enabling data and application portability across TEEs while upholding stringent security standards.


For each application, dstack-kms generates a unique root key derived from the application’s code and configuration. This root key serves as the foundation for a hierarchy of derived keys—such as those for disk encryption, environment variables, and cryptographic signing. Unlike traditional TEEs, where keys are tethered to specific hardware, dstack-kms ensures that keys remain tied to the application itself, facilitating seamless migration between TEE instances.

Key rotation is a critical feature of dstack-kms. In multi-party computation (MPC) scenarios, individual key shares can be rotated without altering the root key, maintaining continuity. In cases of suspected compromise, a full root key rotation is executed, with a handover period to re-encrypt data securely. Governance is enforced through smart contracts, such as KmsAuth, which dictate key distribution rules. Only TEE instances running verified code, as confirmed by attestation, can access these keys. A peer-to-peer network of service nodes, synchronized with on-chain policies, ensures resilience and availability.


The key derivation process is methodical. For example, an application’s certificate authority (CA) key is derived from the root CA key using the application’s unique identifier, while a disk encryption key incorporates both application and instance identifiers. This structure preserves security and portability across deployments.

### dstack-ingress and dstack-gateway: Domain Management

Secure and verifiable communication is handled by dstack-ingress and dstack-gateway, which together enable HTTPS access to TEE applications with zero-trust principles. dstack-gateway operates as a TEE-based reverse proxy, providing pre-registered wildcard domains (e.g., app-id.dstack.com) with automated TLS certificate management. It verifies an application’s attestation before assigning a subdomain, requiring no changes to the application’s code. Conversely, dstack-ingress supports custom domains with minimal integration, offering TLS passthrough for direct, secure client connections.

Both components rely on Zero Trust TLS (ZT-TLS), a mechanism that cryptographically binds TLS certificates to TEE applications. Certificates are generated within the TEE, linked to secrets from dstack-kms, and verified through a chain extending to the blockchain. This ensures that domains are exclusively controlled by authenticated environments, visible to users via standard browser trust indicators. Security is further bolstered by CAA records, restricting certificate issuance to authorized CAs, and Certificate Transparency monitoring to detect unauthorized certificates.

## How It All Works Together

The synergy of dstack’s components is best illustrated through a typical deployment workflow. Developers begin by submitting a container image and policy to dstack. dstack-os provisions a TEE instance, loading the container and measuring its components into hardware registers. The TEE generates an attestation report, which dstack-kms verifies to confirm the instance’s integrity and authorize key release. With keys in hand, the instance encrypts its data and configures its runtime. dstack-gateway or dstack-ingress then establishes a secure HTTPS endpoint, binding it to the TEE via ZT-TLS. Users access the application through this endpoint, confident in its authenticity thanks to browser-verifiable certificates.

This end-to-end process guarantees that only authorized code executes in a trusted environment, with all interactions secured and auditable.


## Security and Trust Model

dstack’s zero-trust security model is rooted in cryptographic verification at every level, eliminating reliance on any single point of trust. The hardware root of trust, provided by TEEs, enforces isolation and measurement. Attestation ensures that only verified components access resources or keys. Smart contracts govern deployment, updates, and key management transparently, while the full chain-of-trust—from hardware to user interaction—remains verifiable. This design aligns with Web3’s trustless paradigm, ensuring that even platform operators cannot undermine the system’s integrity.

## Use Cases and Benefits

dstack’s architecture unlocks powerful use cases for Web3. In AI model training, it enables secure, decentralized computation on confidential datasets across TEE nodes. Autonomous agents benefit from transparent governance and verifiable execution, ensuring predictable behavior. Privacy-preserving analytics become feasible as encrypted data is processed without exposure, fostering collaboration in sensitive domains.

The platform’s benefits are manifold. Portability allows applications to span TEE vendors effortlessly. Enhanced security stems from hardware isolation, key rotation, and decentralized control. Transparency and auditability, driven by blockchain governance, empower users and developers alike.

## Comparison with Other Approaches

dstack stands apart from alternative confidential computing methods. Compared to raw TEE SDKs, it offers a developer-friendly container-based workflow and multi-vendor portability, rather than vendor-specific code customization. Against homomorphic encryption, dstack avoids the need for algorithm redesign, leveraging TEEs and blockchain for practical security and governance. This balance of usability, security, and decentralization makes it uniquely suited for Web3.

## Where to Go Next

If you're researching dstack for your next project and want deeper clarity on its inner workings, start by exploring the [Core Components](/docs/concepts/core-components) reference. This section provides a detailed look at every major component of dstack, complete with architecture diagrams to help you understand how each part fits together.

For hands-on deployment, check out the [Deployment installation and starter guide](/docs/getting-started/installation).

For a technical deep dive, see the [System Design](/docs/concepts/architecture) overview, or read the [Phala Network blog post introducing dstack](https://phala.network/posts/Dstack-A-Zero-Trust-Framework-for-Confidential-Containers).

If you're interested in the security model and want to review the design and threat analysis of specific components, see the following research documents:

🔑 [KMS Security](/docs/security-research/kms-security) – security architecture and threat model for dstack's decentralized key management service  
🖥️ [VMM Security](/docs/security-research/vmm-security) – analysis of the virtual machine monitor and its isolation guarantees  
🌐 [Gateway Security](/docs/security-research/gateway-security) – security model for the TEE-based gateway and ingress  
🛡️ [TDX Attestation](/docs/security-research/tdx-attestation) – technical details on Intel TDX attestation flow  
🗂️ [TDX Attestation System](/docs/security-research/tdx-attestation-system) – system-level overview of attestation orchestration  
🔗 [IOHash Security](/docs/security-research/iohash-security) – integrity and confidentiality of I/O hashing mechanisms  
🔒 [Host API Security](/docs/security-research/host-api-security) – security boundaries and controls for host APIs exposed to enclaves  
👁️ [CT Monitor Security](/docs/security-research/ct-monitor-security) – certificate transparency monitoring and detection of unauthorized certificates  
🤖 [Certbot Security](/docs/security-research/certbot-security) – certificate issuance automation and its security posture  
📜 [Cert Client Security](/docs/security-research/cert-client-security) – client-side certificate management and validation

---

**TL;DR**: dstack is a zero-trust platform for Web3, delivering portable, secure, and verifiable confidential containers through a decentralized architecture.